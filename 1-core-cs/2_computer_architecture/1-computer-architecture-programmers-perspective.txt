-----------------------------------------------------------------------------------
1. A Tour of Computer Systems

----------------------------------------------------------
------------------------- PART 1 -------------------------
------------ Program Structure and Execution -------------
----------------------------------------------------------

2. Representing and Manipulating Information
3. Machine-Level Representation of Programs 
4. Processor Architecture 
5. Optimizing Program Performance 
6. The Memory Hierarchy 

----------------------------------------------------------
------------------------- PART 2 -------------------------
------------- Running Programs on a System  --------------
----------------------------------------------------------

7. Linking 
8. Exceptional Control Flow 
9. Virtual Memory 

----------------------------------------------------------
------------------------- PART 3 -------------------------
----- Interaction and Communication between Programs  ----
----------------------------------------------------------

10. System-Level I/O
11. Network Programming 
12. Concurrent Programming 
-----------------------------------------------------------------------------------


----------------------------------------------------------
1. A Tour of Computer Systems
----------------------------------------------------------

  Information Is Bits + Context
    chars => ASCII => bytes

  Programs Are Translated by Other Programs into Different Forms
    --- compilation system
    preprocessor - modifies .c file according to directives starting with '#'.
    compiler     - translates .c to .s containing assembly-language.
    assembler    - translates .s to .o containing machine-level instructions.
    linker       - link .o file with other precompiled .o files.
    
  It Pays to Understand How Compilation Systems Work

  Processors Read and Interpret Instructions Stored in Memory
    --- hardware organization of a system
    buses       - transfers fixed-size chunks of bytes known as 'words'.
    I/O devices - connected to I/O bus by either controller or adapter.
    main memory - a collection of dynamic random access memory (DRAM).
    processor   - copies data (pointed by PC) into register file from main memory, 
                  executes those instructions (if arithmetic, using APU) and
                  stores results in register file (a collection of word-sized
                  registers), which sends it to main memory.     

  Caches Matter
    L1, L2 (and L3) - increasingly large and decreasingly fast. Have the same 
    performance characteristics as registers but considerable larger. 
    Implemented with static random access memory (SRAM).

    exploiting cache memories correctly can improve performance by an order of
    magnitude.

  Storage Devices Form a Hierarchy
    L0 (registers) <=> L1 (SRAM) <=> L2 (SRAM) <=> L3 (SRAM) <=> L4 (DRAM) <=>
    L5 (local disks) <=> L6 (distributed file systems, web servers).

    each level serves as a cache for the level below.

  The Operating System Manages the Hardware
    |---------------------------------------|
    |         Application programs          |
    |---------------------------------------|
    |                 OS                    |
    |---------------------------------------|
    | Processor | Main memory | I/O devices |
    |---------------------------------------|
    |           |             |             | 
    |           |             |--- Files ---|
    |           |                           |
    |           |------ Virtual memory -----|
    |                                       |
    |--------------- Processes -------------|

    process is the OS's abstraction for running a program. each process has its
    own context (state) and is managed by the OS's kernel. can consist of
    multiple execution units (threads).

    virtual memory
      kernel virtual memory   ↑
      stack                   ↑
      shared libraries        ↑ increasing address index 
      heap                    ↑
      program code and data   ↑

    file - a sequence of bytes (every device is modeled as a file)

  Systems Communicate with Other Systems Using Networks

  Important Themes
    parallelism 
      thread-level concurrency
        multiple programs at the same time - concurrency
        multiple threads per single program - thread-level concurrency 

      instruction-level parallelism
        executing multiple instructions at the same time

      single-instruciton, multiple-data (SIMD) parallelism
        single instruction causing mutliple operations to be performated at the
        same time

    the importance of abstractions in computer systems
      on processor side
        instruction set architecture - one instruction set for all types of
        processor implementations

      on operating system side
        files, virtual memory, processes

----------------------------------------------------------
2. Representing and Manipulating Information
----------------------------------------------------------

The basic definitions of the encodings, derivation such
properties as the range of representable numbers, their bit-level
representations, and the properties of the arithmetic operations.

  The three most important representations of numbers. 
    Unsigned (0 and up)
    Two's-complement (most common way to represent signed ints (- & +))
    Floating point (real numbers)

  Information Storage
    binary (machine) - hexadecimal (easy to communicate) - decimal (humans)

    word size (w-bit) => virtual address space (0 - ([2^w] - 1)); for example,
    32-bit word size limits the vas to 4GB, while 64-bit leads to a vas of 16
    exabytes. 
      -------------------------------------------------
          C declaration                     Bytes
      ------------------------------    ---------------
      Signed          Unsigned          32-bit  64-bit
      -------------------------------------------------
      [signed] char   unsigned char       1       1
      short           unsigned short      2       2
      int             unsigned            4       4
      long            unsigned long       4       8
      int32_t         uint32_t            4       4
      int64_t         uint64_t            8       8
      char*                               4       8
      float                               4       4
      double                              8       8
      -------------------------------------------------
      * Using fixed-size integer types (intN_t where N = 8 16 32 64) is the
      best way for programmers to have close control over data
      representations across different machines and compilers.

      a multi-byte object is stored as a contiguous sequence of bytes, with the
      address of the object given by the smallest address of the bytes used.

      Boolean Algebra
      -----------------------------------------------
        Operation     Math      CS      Sets
      -----------------------------------------------
        NOT           ¬         ~       complement
        AND           ∧         &       intersection 
        OR            ∨         |       union
        NOR           ⊕         ^
      -----------------------------------------------

        0110      0110      0110
      & 1100    | 1100    ^ 1100    ~ 1100
        ----      ----      ----      ----
        0100      1110      1010      0011

      One useful application of bit vectors is to represent finite sets. We can
      encode any subsetA ⊆ {0, 1, . . . , w − 1} with a bit vector [aw−1, . . . ,
      a1, a0], where ai = 1 if and only if i ∈ A. For example, bit vector a =
      [01101001] encodes the set A = {0, 3, 5, 6}.


      shift operations
      ----------------------------------------------------------------
      operation             Value 1      Value 2
      ----------------------------------------------------------------
      Argument x            [0110 0011]  [1001 0101]
      x << 4                [0011 0000]  [0101 0000]
      x >> 4 (logical)      [0000 0110]  [0000 1001]
      x >> 4 (arithmetic)   [0000 0110]  [1111 1001]
      ----------------------------------------------------------------

  Integer Representation
      Unsigned encodings
        [1011] => 1*2^3 + 0*2^2 + 1*2^1 + 1*2^0 = 11
        [1111] => 1*2^3 + 1*2^2 + 1*2^1 + 1*2^0 = 15

      Two's complement encodings (signed)
        [1011] => -1*2^3 + 0*2^2 + 1*2^1 + 1*2^0 = -5
        [1111] => -1*2^3 + 1*2^2 + 1*2^1 + 1*2^0 = -1 
        * most significant bit has negative weight.

      Signed <=> Unsigned (casting)
        the effect of casting is to keep the bit values identical but change
        how these bits are interpreted.

      Expanding the bit representation of a number
        for unsigned, add necessary # of zeros to the left
        for signed, add necessary # of sign-bits to the left

        * One point worth making is that the relative order of conversion from
        one data size to another and between unsigned and signed can affect the
        behavior of a program. 

      Truncating Numbers
        going from w-bit to k-bit means we drop the high-order (w - k) bits. In
        decimal terms, this means

        -- positive truncation (positive overflow)
        d_new = d_old - (2^k). (- could be replaced with mod)

        -- negative truncation (negative overflow)
        d_new = d_old + (2^k).

      One way to avoid int bugs is to never use unsigned numbers except in
      packing word with flags, addresses in systems programming and
      implementing math packages.

  Integer Arithmetic
    Unsigned
      addition:         normal case vs overflow (truncate the result)
      negation:         x = 0 ? x : 2^w - x
      multiplication:   normal vs overflow (truncate the result)

    Two's complement 
      addition:         negative overflow vs normal vs positive overflow
      negation:         x = MIN ? MIN : -x
      multiplication:   negative overflow vs normal vs positive overflow

    Multiplying by Constant

    Dividing by Powers of 2
      Integer division always rounds toward zero. That is, it should round down
      a positive result and round up a negative one. 

  Floating Point
    Value       (-1)^s * M * 2^E
    Binary      [s] [exp] [frac]

    ---------------------------------------------------------
     Part             Meaning
    ---------         ---------------------------------------
      s               sign bit (1 - neg; 0 - pos)

    ---------------------------------------------------------
      exp [E]         E = e - Bias
                        e       k-bit unsigned number 
                        Bias    2^(k-1) - 1

    ---------------------------------------------------------
      frac [M]        fractional value 

            -----------------------------------------------------------------------------
            Exp         Case            Binary representation             Value
            ------      ------------    -------------------------         ---------------
                        Normal          M = 1.f(n-1)...f(1)f(0)           1<=M<2
            -----------------------------------------------------------------------------
            0s          Denormalized    M = 0.f(n-1)...f(1)f(0)           0<=M<1
            -----------------------------------------------------------------------------
            1s          Special*        M = all zeroes || nonzero         infinity || NaN
            -----------------------------------------------------------------------------

    Rounding
      ----------------------------------------------------------------
        Mode                        1.40   1.60   1.50   2.50   –1.50
      ----------------------------------------------------------------
        Round-to-even (default)       1      2      2      2      –2
        Round-toward-zero             1      1      1      2      –1
        Round-down                    1      1      1      2      –2
        Round-up                      2      2      2      3      –1
      ----------------------------------------------------------------

----------------------------------------------------------
3. Machine-Level Representation of Programs 
----------------------------------------------------------

----------- Hardware background -----------
At the lowest level (almost), it runs due to the actions of transistors.
Transistors in digital logic circuits are used mostly as switches. You want the
transistors to be either all the way OFF (no current flow) or all the way ON
(lots of current flow). And you can use the output of one transistor to control
the input of other transistors, so you can construct a complicated circuit by
wiring them up in certain ways. 

Using just a few transistors, you can build very simple logic circuits to
implement binary digital logic (called "Boolean" logic after the guy who
invented it). It turns out that you can build any digital logic function with a
combination of just a few simple circuit types, such as AND/OR/NOT (you can
actually do everything with just one, but no one really does that). By
combining those simple circuits, more complicated circuits can be made (such as
an adder, a multiplexer, etc.). You can use those circuits to make even more
complicated ones. Like a CPU. 
source: https://www.reddit.com/r/explainlikeimfive/comments/17faj8/eli5_how_computer_chips_work/
-------------------------------------------

C => assembly code (object code) => machine code (executable code)

Being able to understand assembly code and how it relates to the
original C code is a key step in understanding how computers execute programs.


Representation and manipulation of data 
  
   Two abstractions are importnat for machine-level programming. 

    a) the format and behavior of a machine-level program is defined by the
    'instruction set architecture' (ISA) defining:
      * the processor state
          a) program counter (address of the next instruction to be executed)

          b) integer register file (16 locations storing 64-bit values)

          c) conditional code registers
          
          d) a set of vector registers (each can hold one or multiple int or
          float values) 

      * the format of instructions (x86-64)
          a) Instructions can range in length from 1 to 15 bytes (commonly used
          ones and ones with more operands require a smaller # of bytes).

          b) The instruction format is designed in such a way that from a given
          starting position, there is a unique decoding of the bytes into
          machine instructions.

          ----------------------------------------------------------------------------------
          C declaration       Intel data type       Assembly-code suffix        Size (bytes)
          ----------------------------------------------------------------------------------
          char                Byte                          b                       1
          short               Word                          w                       2
          int                 Double word                   l                       4
          long                Quad word                     q                       8
          char*               Quad word                     q                       8
          float               Single precision              s                       4
          double              Double precision              l                       8
          ----------------------------------------------------------------------------------


          Integer registers
          ------------------------------------------------------------------
          63                31            15        7
          ------------------------------------------------------------------
          %rax              %eax          %ax       %al       Return value
          %rbx              %ebx          %bx       %bl       Callee saved 
          %rcx              %ecx          %cx       %cl       4th argument 
          %rdx              %edx          %dx       %dl       3rd argument 
          %rsi              %esi          %si       %sil      2nd argument 
          %rdi              %edi          %di       %dil      1st argument 
          %rbp              %ebp          %bp       %bpl      Callee saved 
          %rsp              %esp          %sp       %spl      Stack pointer 
          %r8               %r8d          %r8w      %r8b      5th argument
          %r9               %r9d          %r9w      %r9b      6th argument
          %r10              %r10d         %r10w     %r10b     Callee saved 
          %r11              %r11d         %r11w     %r11b     Callee saved 
          %r12              %r12d         %r12w     %r12b     Callee saved 
          %r13              %r13d         %r13w     %r13b     Callee saved 
          %r14              %r14d         %r14w     %r14b     Callee saved 
          %r15              %r15d         %r15w     %r15b     Callee saved 
          ------------------------------------------------------------------


          Operand forms supported by x86-64
          --------------------------------------------------------------------------------------
          Type                Form              Operand value               Name
          --------------------------------------------------------------------------------------
          Immediate           $Imm              Imm                         Immediate
          Register            ra                R[ra]                       Register
          Memory              Imm               M[Imm]                      Absolute
          Memory              (ra)              M[R[ra]]                    Indirect
          Memory              Imm(rb)           M[Imm + R[rb]]              Base + displacement
          Memory              (rb,ri)           M[R[rb]+ R[ri]]             Indexed
          Memory              Imm(rb,ri)        M[Imm + R[rb]+ R[ri]]       Indexed
          Memory              (,ri,s)           M[R[ri] . s]                Scaled indexed
          Memory              Imm(,ri,s)        M[Imm + R[ri] . s]          Scaled indexed
          Memory              (rb,ri,s)         M[R[rb]+ R[ri] . s]         Scaled indexed
          Memory (general)    Imm(rb,ri,s)      M[Imm + R[rb]+ R[ri] . s]   Scaled indexed
          --------------------------------------------------------------------------------------
          * a, b, i - subscripts
          * $Imm - constant values
          * ra - arbitrary register a, R[ra] - content of that register viewed in the array of registers
          * ra - value; (ra) - address in memory where value is stored
          * Mb[Addr] - a reference to b-byte value stored in memory starting at Addr (subscript b is dropped for simplicity)
          * M[x] - different addressing modes

          Data Movement Instructions
            - mov (movb, movw, movl, movq)
            - movz (movzbw, movzbl, movzwl, movzbq, movzwq)           - move zero-extended 'x' to 'y'
            - movs (movsbw, movsbl, movswl, movsbq, movswq, movslq)   - move sign-extended 'x' to 'y'
            - pushq & popq (onto and from the program stack)

          Arithmetic and Logical Operations
          ---------------------------------------------------------------
          Instruction       Effect            Description
          ---------------------------------------------------------------
          leaq S,D          D ← &S            Load effective address
          inc D             D ← D+1           Increment
          dec D             D ← D−1           Decrement
          neg D             D ← -D            Negate
          not D             D ← ~D            Complement
          add S,D           D ← D + S         Add
          sub S,D           D ← D − S         Subtract
          imul S,D          D ← D ∗ S         Multiply
          xor S,D           D ← D ^ S         Exclusive-or
          or S,D            D ← D | S         Or
          and S,D           D ← D & S         And
          sal k,D           D ← D<<k          Left shift
          shl k,D           D ← D<<k          Left shift (same as sal)
          sar k,D           D ← D>>A k        Arithmetic right shift
          shr k,D           D ← D>>L k        Logical right shift
          ---------------------------------------------------------------

      * the effect each of these instructions will have on the state. 

    b) the memory addresses used by a machine-level program are 'virtual
    addresses'.


Implementation of control.
  Execution of machine instructions can be altered with a jump instruction.

  Condition code registers:
    CF - carry flag; most recent operation yielded a carry
    ZF - zero flag; most recent operation yielded zero
    SF - sign flag; most recent operation yielded a negative value
    OF - overflow flag; most recent operation yielded two's complement overflow

  There are two classes of instructions that set condition codes without
  altering any other registers (arithmetic and logical operations also set
  condition code registers but they also alter other registers).
    ---------------------------------------------------------
    Instruction     Based on      Types
    ---------------------------------------------------------
    cmp S1, S2      S2 - S1       cmpb, cmpw, cmpl, cmpq
    test S1, S2     S1 & S2       testb, testw, testl, testq
    ---------------------------------------------------------

  There are 3 common ways of using condition codes:
    - set a byte to 0 or 1 depending on some combination of condition codes

        The set instructions
        --------------------------------------------------------------------------------------
        Instruction     Synonym         Effect          Set condition
        --------------------------------------------------------------------------------------
        sete  D         setz            D ← ZF                  Equal / zero
        setne D         setnz           D ← ~ ZF                Not equal / not zero
        sets  D                         D← SF                   Negative
        setns D                         D← ~ SF                 Nonnegative
        setg  D         setnle          D ← ~ (SF ^ OF) & ~ZF   Greater (signed >)
        setge D         setnl           D ← ~ (SF ^ OF)         Greater or equal (signed >=)
        setl  D         setnge          D ← SF ^ OF             Less (signed <)
        setle D         setng           D ← (SF ^ OF) | ZF      Less or equal (signed <=)
        seta  D         setnbe          D ← ~ CF & ~ZF          Above (unsigned >)
        setae D         setnb           D ← ~ CF                Above or equal (unsigned >=)
        setb  D         setnae          D ← CF                  Below (unsigned <)
        setbe D         setna           D ← CF | ZF             Below or equal (unsigned <=)
        --------------------------------------------------------------------------------------
        * suffixes denote different conditions (not different operand sizes)

    - conditionally jump to some other part of the program

        The jump instructions
        -----------------------------------------------------------------------------------------
        Instruction         Synonym       Jump condition            Description
        -----------------------------------------------------------------------------------------
        jmp Label                         1                         Direct jump
        jmp *Operand                      1                         Indirect jump
        je  Label           jz            ZF                        Equal / zero
        jne Label           jnz           ~ZF                       Not equal / not zero
        js  Label                         SF                        Negative
        jns Label                         ~SF                       Nonnegative
        jg  Label           jnle          ~(SF ^ OF) & ~ZF          Greater (signed >)
        jge Label           jnl           ~(SF ^ OF)                Greater or equal (signed >=)
        jl  Label           jnge          SF ^ OF                   Less (signed <)
        jle Label           jng           (SF ^ OF) | ZF            Less or equal (signed <=)
        ja  Label           jnbe          ~CF & ~ZF                 Above (unsigned >)
        jae Label           jnb           ~CF                       Above or equal (unsigned >=)
        jb  Label           jnae          CF                        Below (unsigned <)
        jbe Label           jna           CF | ZF                   Below or equal (unsigned <=)
        -----------------------------------------------------------------------------------------

    - conditionally transfer data
        Can only be used in restricted cases, but these cases are fairly common
        and provide a much better match to the operation of modern processors.

        The conditional move instructions
        --------------------------------------------------------------------------------------
        Instruction       Synonym         Move condition        Description
        --------------------------------------------------------------------------------------
        cmove  S, R       cmovz           ZF                    Equal / zero
        cmovne S, R       cmovnz          ~ZF                   Not equal / not zero
        cmovs  S, R                       SF                    Negative
        cmovns S, R                       ~SF                   Nonnegative
        cmovg  S, R       cmovnle         ~(SF ^ OF) & ~ZF      Greater (signed >)
        cmovge S, R       cmovnl          ~(SF ^ OF)            Greater or equal (signed >=)
        cmovl  S, R       cmovnge         SF ^ OF               Less (signed <)
        cmovle S, R       cmovng          (SF ^ OF) | ZF        Less or equal (signed <=)
        cmova  S, R       cmovnbe         ~CF & ~ZF             Above (unsigned >)
        cmovae S, R       cmovnb          ~CF                   Above or equal (Unsigned >=)
        cmovb  S, R       cmovnae         CF                    Below (unsigned <)
        cmovbe S, R       cmovna          CF | ZF               Below or equal (unsigned <=)
        --------------------------------------------------------------------------------------

Implementation of procedures.

  A program can manage the storage required by its procedures using a stack,
  where the stack and the program registers store the information required for
  passing control and data, and for allocating memory.

    a) Passing control.
    b) Passing data.
    b) Allocating and deallocating memory.

Implementation of data structures (arrays, structures & unions).

Out-of-bounds memory references and buffer overflow attacks.

Examining the run-time behavior of a machine-level programs using the GDB
debugger.




----------------------------------------------------------
4. Processor Architecture 
----------------------------------------------------------

Simple instruction set (Y86-64) 

Background on digital hardware design.
  Basic buildign blocks used in a processor, how they are connected and
  operated.
  HCL language

Y86-64 processor based on sequential operation => transformations => Pipelined processor

Logic design and the hardware control language
  combinational logic (a number of logic gates assembled together)
  memory elements
  clock signals







----------------------------------------------------------
5. Optimizing Program Performance 
----------------------------------------------------------
1. Use efficient algorithms and data structures
    a) Eliminate unnecessary work
        - loop inefficiencies 
            * code motion - identify computations performed multiple times but
              whose result won't change.

            * loop unrolling - reduce the # of iterations by computing more
              elements on each iteration. (k x 1 loop unrolling)

        - function calls
        - conditinal tests
        - memory references

2. Write code that compilers can optimize
    a) Understand capabilities and limitations of optimizing compilers
        - know optimization blockers
            * memory aliasing - If a compiler cannot determine whether or not
              two pointers may be aliased, it must assume that either case is
              possible, limiting the set of possible optimizations.

            * function calls - most compilers don't try to determine if a
              function is free of side effects, hence they leave those calls
              intact, limiting the set of possible optimizations.

3. Use parallelism capabilities of modern processors
    a) Microarchitecture of processor
        - instruction level parallelism (ILP)

        - latency bound - a series of operations must be performed in strict
          sequence, limiting the processor to use ILP. 

        - throughput bound - raw computing capacity of the processor's
          functional units, ultimate limit on program performance.
        
        - Modern processors
            * Instruction control unit (ICU)
                a) fetch control
                b) instruction cache
                c) instruction decoder

            * Execution unit (EU)
                a) functional units (store, load, arithmetic, branch)
                    - latency - total time required to perform operation.

                    - issue time - min # of clock cycles between 2 independent
                      operations of the same type (# of operations that can be
                      started on each clock cycle)

                    - capacity - # of functional units capable of performing
                      that operation.

                    * a processor can potentially achieve a throughput of C/I
                      operations per clock cycle (C - capacity, I - issue time)

                b) data cache

        - Enhancing parallelism - breaking latency bound
            * multiple accumulators - for associative and commutative
              operations (int +|*), split the set of combining operations into
              X parts and combine them at the end. That way, the processor
              doesn't need to delay one operation until the prev one finishes.
              (k x k loop unrolling)

            * reassociation transformation
              (k x 1a loop unrolling)

            ** In general, we have found that unrolling a loop and accumulating
            multiple values in parallel is a more reliable way to achieve
            improved program performance (than reassociation transformation).

        - Some limiting factors
            * Regiter Spilling - if a program has a degree of parallelism that
              exceeds # of available registers, then the compiler will resort
              to 'spilling', storing some of the temp values in memory.

            * Branch prediction and misprediction penalties
                - write code that favors conditional data transfers over
                  control transfers.

        - Understanding Memory Performance
            * Load an store 

4. Issues related to optimizing large programs in the real world
    a) High-level design
        - Avoid algos and ds with asymptotically poor performance
    b) Basic coding principles
        - Eliminate excessive func calls
            * move computations out of the loop if possible
            * trade off modularity to gain greater efficiency
        - Eliminate excessive memory refs
            * introduce temp variables to hold intermediate results
            * store result in an array or global variable only when
              finished
    c) Low-level optimizations
        - Unroll loops to reduce overhead and to enable further
          optimizations
        - Increase instruction-level parallelism by using techniques such
          as multiple accumulators and reassociation
        - Rewrite conditional operations in a functional style to enable
          compilation via conditional data transfers



A good strategy: 
  - experiement and analyze
  - look at inner loops (excessive memory references & poor use of registers).
  - identify critical paths, which gives you a lower bound on time and try to
    steer the compiler towards more efficient implementations, which means
    doing a lot of rewriting of a program.


----------------------------------------------------------
6. The Memory Hierarchy 
----------------------------------------------------------
1. Storage technologies
    a) RAMs (random access memories)
        - SRAM (static)   - faster/more expensive; used for cache.
        - DRAM (dynamic)  - slower/less expensive; used for main memory and graphics frame buffers.
    b) ROMs
    c) Disks 
        - Types
            * Rotating
                - Spingle, platters (2 surfaces on each), tracks, sectors (each 512 bytes) & gaps (stores formatting bits that identify sectors)
                - Cylinder - the collection of tracks on all the surfaces that are equidistant from the center of the spindle
                - Recording Zone
                    * the set of cylinders is partitioned into disjoint subsets known as recording zones
                    * each zone consists of a contiguous collections of cylinders
                    * each track in each cylinder in a zone has the same # of
                      sectors, which is determined by the # of sectors that can be
                      packed into the innermost track of the zone.
                - Logical Disk Blocks (0, 1, ... B - 1) - simple view of disk geometry presented to the OS
                    * disk controller stands in-between OS and disk,
                      translating 'logical block' addresses used by the OSJ to
                      (surface, track, sector) triple and copying the data to
                      main memory
            * SSDs (solid state)
                - A sequence of blocks (each is 32-128 pages), pages (each is 512B to 4KB)
                - Flash translation layer stands in-between the OS and the flash memory 

2. Locality
    a) temporal - same loc is likely to be accessed multiple times in the future
    b) spacial - nearby locations are likely to be accessed in the future

3. Memory Hierarchy (L0 <= L1 <= L2 <= L3 <= L4 <= L5 <= L6)

                    --- L0 ---                | CPU registers
                  ----- L1 -----              | SRAM
                ------- L2 -------            | SRAM
              --------- L3 ---------          | SRAM
            ----------- L4 -----------        | DRAM
          ------------- L5 -------------      | local disks
        --------------- L6 ---------------    | distributed file systems, web servers

        ------------------------------------------------------------------------------------------------------------
        Type              What cached               Where cached            Latency (cycles)    Managed by
        ------------------------------------------------------------------------------------------------------------
        CPU registers     4-byte or 8-byte words    On-chip CPU registers   0                   Compiler
        TLB               Address translations      On-chip TLB             0                   Hardware MMU
        L1 cache          64-byte blocks            On-chip L1 cache        4                   Hardware
        L2 cache          64-byte blocks            On-chip L2 cache        10                  Hardware
        L3 cache          64-byte blocks            On-chip L3 cache        50                  Hardware
        Virtual memory    4-KB pages                Main memory             200                 Hardware + OS
        Buffer cache      Parts of files            Main memory             200                 OS
        Disk cache        Disk sectors              Disk controller         100,000             Controller firmware
        Network cache     Parts of files            Local disk              10,000,000          NFS client
        Browser cache     Web pages                 Local disk              10,000,000          Web browser
        Web cache         Web pages                 Remote server disks     1,000,000,000       Web proxy server
        ------------------------------------------------------------------------------------------------------------

    a) Cache hits/missses
        - Types of misses
            * conflict miss 
            * capacity miss
    b) Organization
        - Sets, lines (each consists of [1] valid bit, [m - (b + s)] tag bits, and [2^b] bytes,
          where s = 2^s sets in a cache and m = # of bits in an address)
        - Cache address
            ---------------------------------------------------
            |   tag bits  |   set bits  |   block-offset bits |
            ---------------------------------------------------
            m - 1                                             0
            * set bits correspond to unsigned set number (0 to S-1)
            * tag bits identify the line in the set
            * block-offset leads us to the start bit of data we are interested in

    c) Types
        - Direct-mapped cache       - one-line-per-set cache 
        - E-way associative cache   - E-lines-per-set cache
        - Fully associative cache   - a single set containing all lines 
        - i-cache (read-only)       - can only hold instructions
        - d-cache                   - can only hold data
        - unified-cache             - can hold both instructions and data
    d) Performance
        - miss rate       = #misses/#references
        - hit rate        = 1 - misses
        - hit time        = set selection + line identification + word selection
        - miss penalty    = additional time required because of a miss
            ------------------------------------------------------
            cache       penalty (clock cycles)
            ------------------------------------------------------
            L1          10  (L1 has to get data from L2)
            L2          50  (L2 has to get data from L3)
            L3          200 (L3 has to get data from main memory)
            ------------------------------------------------------
    
    e) Conclusion
        The performance of the memory system is a mountain of temporal and
        spatial locality whose elevations can vary by over an order of
        magnitude.Wise programmers try to structure their programs so that they
        run in the peaks instead of the valleys. The aim is to exploit temporal
        locality so that heavily used words are fetched from the L1 cache, and
        to exploit spatial locality so that as many words as possible are
        accessed from a single L1 cache line.

        - Focus your attention on the inner loops, where the bulk of the computations
          and memory accesses occur.
        - Try to maximize the spatial locality in your programs by reading data objects
          sequentially, with stride 1, in the order they are stored in memory.
        - Try to maximize the temporal locality in your programs by using a data object
          as often as possible once it has been read from memory


----------------------------------------------------------
7. Linking 
----------------------------------------------------------
Linkers allow us to decompose large programs into smaller, more manageable
modules that can be modified and compiled/linked separately.

1. Preprocessor (.i) => compiler (.s) => assembler (.o) => linker (progam) => loader => CPU/memory
2. Obj files
    a) Types
        - relocatable
            * Relocatable obj file format
                -------------------------
                |     ELF header        |   - metadata about this file
                -------------------------
                |       .text           |   - machine code of the compiled program
                |       .rodata         |   - read-only data (e.g. format strs & jump tables)
                |       .data           |   - initialized global and static C variables [1] 
                |       .bss            |   - uninitialized global and static variables (incl. ones that are equal 0)
                |       .symtab         |   - symbol table with info about funcs and global variables defined/ref'd in the program
                |       .rel.text       |   - a list of locs in .text section that need to be modified 
                |       .rel.data       |   - see above
                |       .debug          |   - debug symbol table
                |       .line           |   - mapping between C source program and machine instruction in .text
                |       .strtab         |   - string table for .symtab and .debug and for section names in section headers
                -------------------------
                | Section haeder table  |   - locs and sizes of various sections
                -------------------------
                [1] - local nonstatic variables are managed at run time on the stack
                * linker doesn't care about local variables

            * Symbol resolution
                - Duplicates in regular files
                    - Rule 1. Multiple strong symbols with the same name are not allowed.
                    - Rule 2. Given a strong symbol and multiple weak symbols with the same name, choose the strong symbol.
                    - Rule 3. Given multiple weak symbols with the same name, choose any of the weak symbols.
                      * initialized = strong; uninitialized = weak
                      * rules 2 & 3 are a source of nasty bugs

                -  Resolution with static libraries (a package of related obj modules in a single file)
                    * Process
                        - Include the header file (.h) of the shared library in your
                          file (.h => symbols)
                        - Pass shared library archive file (.a) to the linker with
                          your own relocatable obj files (.a => definitions of
                          the above symbols) [1]

                        [1] the linker scans input files in the same order they
                          appear in the compiler driver's command line (ordering of inputs matters). 
                          Hence if the definition (e.g., in static library archive
                          file) comes before the reference (e.g., in user file that used
                          the library) and not after, the linker cannot resolve
                          that symbol and will fail. So, the general rule with
                          libraries is to place them at the end of command line.

            * Relocation
                - Relocating sections and symbol definitions
                - Relocating symbol references within sections
                    * relocation entries (when the assempler encounters
                      references to objects whose ultimate locs are unknown, it
                      generates relocation entries for those references)
  
        - executable
            * Executable obj file format
                -------------------------
                |     ELF header        |   - metadata about this file
                -------------------------
                |  Segment header table |   - maps contiguous file sections to run-time memory segments
                -------------------------
                |       .init           |   - defines _init, which is called by the program init code
                |       .text           |   - machine code of the compiled program
                |       .rodata         |   - read-only data (e.g. format strs & jump tables)
                |       .data           |   - initialized global and static C variables [1] 
                |       .bss            |   - uninitialized global and static variables (incl. ones that are equal 0)
                |       .symtab         |   -- 
                |       .debug          |    | not loaded into memory
                |       .line           |    |
                |       .strtab         |   -- 
                -------------------------
                | Section haeder table  |   - locs and sizes of various sections
                -------------------------

            * Linux x86-64 run-time memory image (when the above loads into memory)

                ----------------------------      2^(48)-1
                |       User stack         |
                |   (created at run time)  |
                ---------------------------- %esp (stack pointer)
                |             ↓            |
                |             ↑            |
                ----------------------------
                | Memory-mapped region for |
                |     shared libraries     |
                ----------------------------
                |                          |
                |             ↑            |
                ---------------------------- brk
                |      Run-time heap       |
                |   (created by malloc)    |
                ---------------------------- --
                |   Read/write segment     |  |
                |      (.data,.bss)        |  |
                ----------------------------  | loaded from executable file
                |   Read-only code segment |  |
                |   (.init,.text,.rodata)  |  |
                ---------------------------- --   0x400000
                |                          |
                ----------------------------      0

        - shared
            * shared libraries - modern sofware innovation that address the disadvantages of
              static libraries (for each running program, you must have separate
              copy, which is wasteful of memory space)
            * loaded at an arbitrary memory address and linked with a prog in memory
            * only one copy of the library across one file system 
            * linking is done in two phases:
                - regular linking except no actual copying (from library to
                  to-be-created final executable obj file) takes place
                - partially linked obj file is then loaded into memory and is
                  dynamically linked at run-time
